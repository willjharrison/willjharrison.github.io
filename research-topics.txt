<p>
Our group is not interested in the brain for the sake of it—we want to understand how biological material gives rise to conscious experience. We therefore recognise that we need robust measurements of people's sensory and cognitive abilities. Without robust psychophysical assays of perceptual and cognitive function, we do not know what to look for in the brain. Our group therefore emphasises the important role of clear, compelling, and reproducible behavioural phenomena as a starting place for all other investigation.
</p>

<details>
  <summary>Robust Psychophysics to Describe Perception and Cognition</summary>
  <p>We design controlled behavioural experiments that precisely measure perceptual thresholds, biases, and decision rules. These methods provide the foundation for all of our work, ensuring that our models are constrained by high-quality data. My contributions include the development of paradigms that separate perceptual sensitivity from decision criteria, allowing us to map specific computations in sensory and cognitive domains.</p>
</details>

<details>
  <summary>Eye Tracking to Understand Active Exploration</summary>
  <p>Perception is not passive: we move our eyes to sample the world. Using high-resolution eye tracking, we study how gaze patterns reveal the strategies people use to extract information. Our work has linked oculomotor behaviour with moment-to-moment perception, showing how active sampling is tuned to both task demands and neural coding constraints.</p>
</details>

<details>
  <summary>Working Memory Models to Understand Storage Limits</summary>
  <p>Visual working memory has strict capacity and precision limits. We develop and test models that explain how information is stored, degraded, and lost over time. This work has clarified trade-offs between the number of items remembered and the fidelity with which they are represented, providing a mechanistic understanding of memory constraints.</p>
</details>

<details>
  <summary>Peripheral Vision to Understand Lossy Encoding</summary>
  <p>The periphery encodes information less precisely than the fovea, but in structured and lawful ways. Our research has shown how crowding, pooling, and other encoding limitations shape perception outside the centre of gaze. These findings highlight the principles of lossy compression in visual encoding, linking retinal and cortical organisation to everyday perceptual experience.</p>
</details>

<details>
  <summary>Meta-Cognition to Understand How We Think About Thinking</summary>
  <p>We do not only perceive and remember—we also evaluate the quality of those processes. Our work investigates how confidence judgements are formed and how they relate to objective performance. By measuring both decisions and their accompanying confidence, we seek to uncover the computations that allow people to monitor and control their own cognition.</p>
</details>

<details>
  <summary>Computational Modelling to Understand Brain Algorithms</summary>
  <p>At the core of our program is the development of computational models that formalise hypotheses about brain function. We build Bayesian observer models that take as input the same visual stimulus as experiment volunteers, and use efficient coding frameworks to test how neural populations might represent and combine information. These models allow us to bridge behaviour, neural coding, and environmental statistics in a unified framework.</p>
</details>

<details>
  <summary>Neuro-Imaging to Quantify Uncertainty in Neural Encoding</summary>
  <p>To connect behavioural models with neural data, we use imaging approaches to estimate the fidelity and uncertainty of neural population codes. We analyse fMRI, EEG, and MEG datasets to decode stimulus representations and link them with psychophysical measures of uncertainty. This work aims to show how the brain’s probabilistic computations manifest both in the cortex and in perception.</p>
</details>